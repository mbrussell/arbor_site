{
  "hash": "b2d7c48dd48a99726499f4c2fb995302",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Bootstrapped resampling to model tree biomass \ndescription: \"Bootstrapping works well with messy data and with small samples.\"\nauthor: Matt Russell\ndate: '2023-04-12'\nslug: [bootstrapped-resampling-to-model-tree-biomass]\ncategories:\n  - Statistics\ntags:\n  - analytics\n  - tidymodels\n  - bootstrap\n  - forest measurements\n  - statistics\nimage: ash_stump.png  \n---\n\n\n<center>\n\n![](ash_stump.png){width=500px}\n</center>\n\n## \n\nIn one of the first presentations I gave as a graduate student, I discussed a set of regression equations that fit a nonlinear model predicting a forest growth index for several species. As all graduate students do, I spent considerable time preparing my slides and practicing my talk. The presentation went well.\n\nI used a data splitting approach in my analysis that I presented on, a common technique that trains a model on a large portion of the data (usually around 70%) then tests it on a smaller portion of data not used in model fitting (usually around 30%). After my presentation, a faculty member came up to me and asked, \"You ever considered bootstrapping?\"\n\nUp to then, I think I learned about bootstrapping in half a lecture in one of my statistics courses. In my defense, there weren't great tutorials on how to do bootstrapping in my own field of applied forest science, and statistical packages in software like R weren't as common as they are today. That day, I learned that bootstrapping regression models could be a viable alternative to traditional regression approaches.\n\nIn a nutshell, bootstrapping is more computationally intensive but doesn't rely on distribution assumptions (i.e., the assumption of errors that are normally distributed). It works well with data that are \"messy\" and in situations where only a small number of samples are available.\n\nThe general approach to bootstrapping a regression model is to (1) iteratively sample a subset of the data with replacement, (2) fit the regression model to each subset, and (3) output the regression coefficients from each subset so that you can visualize and interpret results. \n\nIn this tutorial, I use bootstrapping with with **tidymodels** package in R and apply it to estimating tree biomass for several species from the southern United States.\n\n## Tree biomass data\n\nTo begin, we'll use many functions from the **tidyverse** package in R to work with the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n::: {.cell}\n\n:::\n\n\nThe objective of this post is to fit a subsample of models that determine the aboveground biomass of trees using tree diameter as a predictor variable. I've gathered data from [LegacyTreeData](http://www.legacytreedata.org/), an online repository of individual tree measurements such as volume, weight, and wood density. \n\nI queried the database to provide all tree measurements for pine species the US State of Georgia. (You can [find the raw data here](https://github.com/mbrussell/myblog/blob/master/content/post/2023-04-12-bootstrapped-resampling-estimates-to-predict-tree-height/ga_tree.csv), and I've previously [written about these data](https://arbor-analytics.com/post/fit-many-models-with-broom/).)\n\nThere are 566 observations from six species that contain a value for the tree's diameter at breast height(`ST_OB_D_BH`; cm) and its aboveground dry weight (`AG_DW`; kg). In this data set, most trees are small in diameter and do not weigh a lot: \n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(tree, aes(ST_OB_D_BH, AG_DW, col = Species)) +\n  geom_point() +\n  labs(x = \"Diameter at breast height (cm)\", \n       y = \"Aboveground dry weight (kg)\") +\n  theme(panel.background = element_rect(fill = \"NA\"),\n        axis.line = element_line(color = \"black\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nHere is a summary of the data we'll use in the modeling exercise:\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-bordered\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Summary statistics for diameter at breast height (DBH; cm) \n             and aboveground dry weight (weight; kg) for six pine species from the southeastern US.</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Species </th>\n   <th style=\"text-align:right;\"> Num trees </th>\n   <th style=\"text-align:right;\"> Mean DBH </th>\n   <th style=\"text-align:right;\"> Max DBH </th>\n   <th style=\"text-align:right;\"> Min DBH </th>\n   <th style=\"text-align:right;\"> Mean weight </th>\n   <th style=\"text-align:right;\"> Max weight </th>\n   <th style=\"text-align:right;\"> Min weight </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Loblolly pine </td>\n   <td style=\"text-align:right;\"> 186 </td>\n   <td style=\"text-align:right;\"> 7.9 </td>\n   <td style=\"text-align:right;\"> 21.6 </td>\n   <td style=\"text-align:right;\"> 1.8 </td>\n   <td style=\"text-align:right;\"> 16.8 </td>\n   <td style=\"text-align:right;\"> 191.8 </td>\n   <td style=\"text-align:right;\"> 0.8 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Shortleaf pine </td>\n   <td style=\"text-align:right;\"> 100 </td>\n   <td style=\"text-align:right;\"> 7.6 </td>\n   <td style=\"text-align:right;\"> 12.4 </td>\n   <td style=\"text-align:right;\"> 2.8 </td>\n   <td style=\"text-align:right;\"> 11.9 </td>\n   <td style=\"text-align:right;\"> 35.6 </td>\n   <td style=\"text-align:right;\"> 0.8 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Longleaf pine </td>\n   <td style=\"text-align:right;\"> 80 </td>\n   <td style=\"text-align:right;\"> 7.6 </td>\n   <td style=\"text-align:right;\"> 12.4 </td>\n   <td style=\"text-align:right;\"> 3.0 </td>\n   <td style=\"text-align:right;\"> 16.5 </td>\n   <td style=\"text-align:right;\"> 54.0 </td>\n   <td style=\"text-align:right;\"> 0.9 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Slash pine </td>\n   <td style=\"text-align:right;\"> 80 </td>\n   <td style=\"text-align:right;\"> 7.6 </td>\n   <td style=\"text-align:right;\"> 12.4 </td>\n   <td style=\"text-align:right;\"> 3.0 </td>\n   <td style=\"text-align:right;\"> 13.9 </td>\n   <td style=\"text-align:right;\"> 48.0 </td>\n   <td style=\"text-align:right;\"> 0.9 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Virginia pine </td>\n   <td style=\"text-align:right;\"> 80 </td>\n   <td style=\"text-align:right;\"> 7.7 </td>\n   <td style=\"text-align:right;\"> 12.4 </td>\n   <td style=\"text-align:right;\"> 2.5 </td>\n   <td style=\"text-align:right;\"> 17.1 </td>\n   <td style=\"text-align:right;\"> 58.1 </td>\n   <td style=\"text-align:right;\"> 1.0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Eastern white pine </td>\n   <td style=\"text-align:right;\"> 40 </td>\n   <td style=\"text-align:right;\"> 7.5 </td>\n   <td style=\"text-align:right;\"> 12.4 </td>\n   <td style=\"text-align:right;\"> 2.5 </td>\n   <td style=\"text-align:right;\"> 12.5 </td>\n   <td style=\"text-align:right;\"> 30.7 </td>\n   <td style=\"text-align:right;\"> 1.0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Nonlinear regression model of tree biomass\n\nFrom the previous graph and what we know about tree size-mass relationships, nonlinear equation forms work best. In this case, we'll refit the classic [Jenkins et al. tree biomass models](https://www.fs.usda.gov/research/treesearch/6996) using our the pine tree data. The model form is an exponential model which we'll save in R as the `bio_pred` object. \n\nWith most nonlinear applications in R, we'll also need to specify starting values for each coefficient. Here we'll use the values for the pine species group from the Jenkins et al. publication and store them in the `start_vals` object:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbio_pred <- as.formula(AG_DW ~ exp(b0 + b1*log(ST_OB_D_BH)))\n\nstart_vals <- list(b0 = -2.5356, b1 = 2.4349)\n```\n:::\n\n\nA classic use of these data would be to use the `nls()` function in R. Here's how we can specify that:  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nm.bio <- nls(bio_pred,\n             start = start_vals,\n             data = tree)\nsummary(m.bio)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFormula: AG_DW ~ exp(b0 + b1 * log(ST_OB_D_BH))\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \nb0 -3.31397    0.08806  -37.63   <2e-16 ***\nb1  2.75972    0.03339   82.65   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.657 on 564 degrees of freedom\n\nNumber of iterations to convergence: 4 \nAchieved convergence tolerance: 5.075e-06\n```\n\n\n:::\n:::\n\n\nWe can see that each coefficient has a small *p*-value. If we compare the size and magnitude of the coefficients to the ones presented in Jenkins et al., we see that they are similar, giving us some confidence in our analysis moving forward.\n\n## Bootstrapping regressions with tidymodels\n\nThe [**tidymodels** package in R](https://www.tidymodels.org/packages/) has a number of helpful tools for performing regressions and handling their output. The package draws from many useful functions from other packages like **rsample** and **broom**:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\n```\n:::\n\n\nOne helpful function is `tidy()`, which compiles regression output into a \"tibble\", or a data set that can be used in subsequent analyses. I love this function because you can use the tibble that it creates by merging it to a new data set or visualizing the output: \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(m.bio)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term  estimate std.error statistic   p.value\n  <chr>    <dbl>     <dbl>     <dbl>     <dbl>\n1 b0       -3.31    0.0881     -37.6 5.95e-156\n2 b1        2.76    0.0334      82.7 2.28e-317\n```\n\n\n:::\n:::\n\n\nBefore we bootstrap, we'll create a generic function to perform the subset of regressions: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_fx <- function(split){\n  nls(bio_pred, data = analysis(split), start = start_vals)\n  }\n```\n:::\n\n\nThe `bootstraps()` function from **tidymodels** performs the bootstrap resampling. We'll ask it to resample from the `tree` data set a total of 500 times. We set `apparent = TRUE` to take one additional sample in the analysis, a requirement for some estimates that are produced after the sampling.\n\nWe use the `map()` function to create a data frame of modeling results, including the coefficients. This is stored in `bio_boot`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\n\nbio_boot <-\n  bootstraps(tree, times = 500, apparent = TRUE) %>%\n  mutate(models = map(splits, ~ fit_fx(.x)), \n      coef_info = map(models, tidy))\n\nbio_boot\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Bootstrap sampling with apparent sample \n# A tibble: 501 × 4\n   splits            id           models coef_info       \n   <list>            <chr>        <list> <list>          \n 1 <split [566/202]> Bootstrap001 <nls>  <tibble [2 × 5]>\n 2 <split [566/208]> Bootstrap002 <nls>  <tibble [2 × 5]>\n 3 <split [566/218]> Bootstrap003 <nls>  <tibble [2 × 5]>\n 4 <split [566/200]> Bootstrap004 <nls>  <tibble [2 × 5]>\n 5 <split [566/206]> Bootstrap005 <nls>  <tibble [2 × 5]>\n 6 <split [566/206]> Bootstrap006 <nls>  <tibble [2 × 5]>\n 7 <split [566/207]> Bootstrap007 <nls>  <tibble [2 × 5]>\n 8 <split [566/211]> Bootstrap008 <nls>  <tibble [2 × 5]>\n 9 <split [566/201]> Bootstrap009 <nls>  <tibble [2 × 5]>\n10 <split [566/220]> Bootstrap010 <nls>  <tibble [2 × 5]>\n# ℹ 491 more rows\n```\n\n\n:::\n:::\n\n\nIf we wanted to look at a specific sample (say samples 1 and 167), we could extract the output directly from `bio_boot`. Note the differences in the b0 and b1 coefficients between the two samples:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbio_boot$models[[1]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNonlinear regression model\n  model: AG_DW ~ exp(b0 + b1 * log(ST_OB_D_BH))\n   data: analysis(split)\n    b0     b1 \n-3.505  2.848 \n residual sum-of-squares: 15302\n\nNumber of iterations to convergence: 6 \nAchieved convergence tolerance: 2.409e-06\n```\n\n\n:::\n\n```{.r .cell-code}\nbio_boot$models[[167]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNonlinear regression model\n  model: AG_DW ~ exp(b0 + b1 * log(ST_OB_D_BH))\n   data: analysis(split)\n    b0     b1 \n-3.139  2.682 \n residual sum-of-squares: 14350\n\nNumber of iterations to convergence: 3 \nAchieved convergence tolerance: 9.827e-06\n```\n\n\n:::\n:::\n\n\nA more efficient way might be to extract the coefficients and store them in a data set named `bio_coef`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbio_coef <- \n  bio_boot %>%\n  select(-splits) %>%\n  unnest(cols = c(coef_info)) %>%\n  select(id, term, estimate) \n\nbio_coef\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,002 × 3\n   id           term  estimate\n   <chr>        <chr>    <dbl>\n 1 Bootstrap001 b0       -3.50\n 2 Bootstrap001 b1        2.85\n 3 Bootstrap002 b0       -3.27\n 4 Bootstrap002 b1        2.73\n 5 Bootstrap003 b0       -3.25\n 6 Bootstrap003 b1        2.73\n 7 Bootstrap004 b0       -3.27\n 8 Bootstrap004 b1        2.73\n 9 Bootstrap005 b0       -3.35\n10 Bootstrap005 b1        2.79\n# ℹ 992 more rows\n```\n\n\n:::\n:::\n\n\nThen, we can visualize the distribution in the coefficients from the 500 samples in the form of a histogram:\n\n\n::: {.cell}\n\n```{.r .cell-code}\np.coef <- bio_coef %>% \n  ggplot(aes(x = estimate)) + \n  geom_histogram(bins = 20, col = \"white\") + \n  facet_wrap(~ term, scales = \"free_x\")\n\np.coef\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nWhile it's helpful to visualize the distribution of coefficients, we also may want to quantify the key quantiles of them. The `int_pctl()` function calculates confidence intervals from bootstrap samples. Here are the lower and upper confidence interval values from the bootstrapped estimates:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npct_ints <- int_pctl(bio_boot, coef_info, alpha = 0.05)\n\npct_ints\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  term  .lower .estimate .upper .alpha .method   \n  <chr>  <dbl>     <dbl>  <dbl>  <dbl> <chr>     \n1 b0     -3.82     -3.21  -2.08   0.05 percentile\n2 b1      2.23      2.72   2.96   0.05 percentile\n```\n\n\n:::\n:::\n\n\nWe can add these values to our visualization to see that the upper and lower bounds (in blue) are not uniformly distributed around the mean estimate (in orange) for each coefficient:\n\n\n::: {.cell}\n\n```{.r .cell-code}\np.coef + \n  geom_vline(data = pct_ints, aes(xintercept = .estimate), \n             col = \"orange\", linewidth = 2, linetype = \"dashed\") + \n  geom_vline(data = pct_ints, aes(xintercept = .lower), \n             col = \"blue\") + \n  geom_vline(data = pct_ints, aes(xintercept = .upper), \n             col = \"blue\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nNext, we can use the `augment()` function to obtain the fitted and residual values for each resampled data point. We'll sample from 250 runs to limit some of our output:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboot_aug <- \n  bio_boot %>% \n  sample_n(250) %>% \n  mutate(augmented = map(models, augment)) %>% \n  unnest(augmented)\n\nboot_aug\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 141,500 × 8\n   splits            id       models coef_info  AG_DW ST_OB_D_BH .fitted  .resid\n   <list>            <chr>    <list> <list>     <dbl>      <dbl>   <dbl>   <dbl>\n 1 <split [566/218]> Bootstr… <nls>  <tibble>  12.1         6.86   7.32   4.74  \n 2 <split [566/218]> Bootstr… <nls>  <tibble>   0.862       3.05   0.763  0.0987\n 3 <split [566/218]> Bootstr… <nls>  <tibble>  53.8        12.2   36.4   17.4   \n 4 <split [566/218]> Bootstr… <nls>  <tibble>   1.18        2.54   0.459  0.720 \n 5 <split [566/218]> Bootstr… <nls>  <tibble>  18.3        10.9   26.8   -8.53  \n 6 <split [566/218]> Bootstr… <nls>  <tibble>   8.66        6.86   7.32   1.34  \n 7 <split [566/218]> Bootstr… <nls>  <tibble>  20.9        11.4   30.4   -9.52  \n 8 <split [566/218]> Bootstr… <nls>  <tibble>  11.9         7.62   9.82   2.11  \n 9 <split [566/218]> Bootstr… <nls>  <tibble>   5.90        5.33   3.63   2.26  \n10 <split [566/218]> Bootstr… <nls>  <tibble>   4.40        5.84   4.68  -0.283 \n# ℹ 141,490 more rows\n```\n\n\n:::\n:::\n\n\nThen, we can visualize how the resampling approach with bootstrapping results in varying relationships in predicting aboveground tree biomass based on tree diameter, with each bootstrapped model shown in blue: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(boot_aug, aes(x = ST_OB_D_BH, y = AG_DW )) +\n  geom_line(aes(y = .fitted, group = id), alpha = .2, col = \"blue\") +\n  geom_point() +\n  labs(x = \"Diameter at breast height (cm)\", \n       y = \"Aboveground dry weight (kg)\") +\n  theme(panel.background = element_rect(fill = \"NA\"),\n        axis.line = element_line(color = \"black\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n## Comparing biomass model predictions\n\nFinally, we may be interested to see how the different models we've considered result in predictions of biomass. The `tree_test` object is a small data set that applies each of three predictions from the models we've considered:\n\n* The original Jenkins et al. 2004 model for the pine species group,\n* The nonlinear least squares model fit with parametric techniques (from the `m.bio` object), and\n* The NLS models fit with bootstrap estimates.\n\nThe `AG_DW_pred` variable stores the predicted biomass:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_test <- tibble(model = rep(c(\"Jenkins et al. 2004\", \n                                  \"NLS refit\", \n                                  \"NLS refit, with bootstrap\"),\n                                c(20, 20, 20)),\n                    dbh = rep(seq(1, 20, by = 1), 3))\n\nfx_AG_DW <- function(model, ST_OB_D_BH){\n  if(model == \"Jenkins et al. 2004\")\n    {AG_DW <- exp(-2.5356 + 2.4349*log(ST_OB_D_BH))}\n  else if(model == \"NLS refit\")\n    {AG_DW <- exp(-3.31397 + 2.75972*log(ST_OB_D_BH))}\n  else if(model == \"NLS refit, with bootstrap\")\n    {AG_DW <- exp(as.numeric(pct_ints[1,3]) + \n                    as.numeric(pct_ints[2,3])*log(ST_OB_D_BH))}\n  else(AG_DW <- 0)\n  return(AG_DW = AG_DW)\n}\n\ntree_test$AG_DW_pred <- mapply(fx_AG_DW, \n                               model = tree_test$model, \n                               ST_OB_D_BH = tree_test$dbh)\n```\n:::\n\n\nThen, we can plot the models to observe their differences. The original Jenkins et al. model underpredicts at larger diameters relative to the models that were refit to the data:  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(tree_test, aes(x = dbh, y = AG_DW_pred, col = model)) +\n  geom_line() +\n  geom_point() +\n  labs(x = \"Diameter at breast height (cm)\", \n       y = \"Predicted aboveground dry weight (kg)\") +\n  theme(panel.background = element_rect(fill = \"NA\"),\n        axis.line = element_line(color = \"black\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n## Conclusion\n\nUsing bootstrapping to estimate regression coefficients has many benefits. It works well with a small number of observations and the analyst does not need to rely on distribution assumptions about the data and the resulting error terms. The **tidymodels** package makes performing bootstrap methods a breeze, and a variety of functions enable the analyst to visualize and interpret output from the bootstrap samples.\n\n--\n\n*Special thanks to Julia Silge's [excellent tutorial on tidymodels](https://juliasilge.com/blog/beer-production/) that inspired this post, and the [tidymodels page from Posit](https://www.tidymodels.org/learn/statistics/bootstrap/) for helpful code.*",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}